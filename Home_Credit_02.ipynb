{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNHA8RHzA1K0QG9aCikguDd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ella00100/Kaggle_competition/blob/main/Home_Credit_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Introduction to Manual Feature Engineering\n",
        "\n",
        "- 이 노트북에서는 홈 크레딧 기본 위험 경쟁을 위한 기능을 직접 만드는 방법에 대해 알아봅니다. 이전 노트북에서는 모델을 구축하기 위해 애플리케이션 데이터만 사용했습니다. 우리가 이 데이터에서 만든 최고의 모델은 리더보드에서 약 0.74점을 얻었습니다. 이 점수를 개선하려면 다른 데이터 프레임의 정보를 더 많이 포함해야 합니다. \n",
        "\n",
        "- 여기서는 Bureau의 정보와 Bureau_balance 데이터를 사용하는 방법을 살펴보겠습니다. 이러한 데이터 파일의 정의는 다음과 같습니다:\n",
        "\n",
        "- Bureau: 고객이 Home Credit에 보고한 다른 금융 기관과의 이전 대출에 대한 정보. 이전 대출에는 각각의 행이 있습니다.\n",
        "\n",
        "- bureau_balance: 이전 대출에 대한 월별 정보. 각 달에는 고유한 행이 있습니다.\n",
        "manual feature engineering은 지루한 프로세스가 될 수 있으며(기능 툴과 함께 자동화된 기능 엔지니어링을 사용하는 이유입니다!) 종종 도메인 전문 지식에 의존합니다. 대출에 대한 도메인 지식과 채무 불이행 가능성을 높이는 요소가 제한되어 있기 때문에, 대신 최종 교육 데이터 프레임에 가능한 한 많은 정보를 얻는 데 집중할 것입니다. 그 아이디어는 모델이 우리가 결정해야 하는 것보다 어떤 기능이 중요한지 알게 될 것이라는 것입니다. 기본적으로, 우리의 접근 방식은 가능한 한 많은 기능을 만든 다음 이 모든 기능을 모델이 사용하도록 제공하는 것입니다! 나중에 모델의 기능 중요도나 PCA와 같은 다른 기술을 사용하여 기능 축소를 수행할 수 있습니다.\n",
        "\n",
        "- manual feature engineering 프로세스에는 많은 Pandas 코드, 약간의 인내심 및 많은 우수한 연습 조작 데이터가 포함됩니다. 자동화된 기능 엔지니어링 도구를 사용할 수 있게 되기 시작했지만, 기능 엔지니어링은 여전히 많은 데이터 논쟁을 사용하여 잠시 동안 수행해야 합니다."
      ],
      "metadata": {
        "id": "VqeNH9imF4En"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Crzbd-l0Fv9D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.style.use('fivethirtyeight')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ex: Counts of a client's previous loans\n",
        "\n",
        "- manual feature engineering의 일반적인 프로세스를 설명하기 위해 먼저 다른 금융 기관에서 고객의 이전 대출 금액을 간단히 계산합니다. 이를 위해서는 노트북 전체에 걸쳐 많은 Pandas 작업이 필요합니다:\n",
        "\n",
        "  - groupby: 데이터 프레임을 열별로 그룹화합니다. 이 경우 고유 고객인 SK_ID_CURR 열별로 그룹화합니다\n",
        "\n",
        "  - agg: 열의 평균을 구하는 것과 같은 그룹화된 데이터에 대해 계산을 수행합니다. 함수(grouped_df.mean())를 직접 호출하거나 변환 목록(grouped_df.agg([mean, max, min, sum])과 함께 agg 함수를 사용할 수 있습니다\n",
        "\n",
        "  - merge: 집계된 통계를 적절한 클라이언트와 일치시킵니다. 원래 교육 데이터를 SK의 계산된 통계와 병합해야 합니다클라이언트에 해당 통계가 없는 셀에 NaN을 삽입할 ID_CURR 열\n",
        "또한 사전으로 이름을 바꿀 열을 지정하는 (이름 바꾸기) 기능을 상당히 많이 사용합니다. 이것은 우리가 생성하는 새로운 변수를 추적하는 데 유용합니다.\n",
        "\n",
        "- 이것은 많은 것처럼 보일 수 있습니다. 그래서 우리는 결국 이 과정을 수행하기 위한 함수를 작성할 것입니다. 먼저 수작업으로 구현하는 방법을 살펴보겠습니다."
      ],
      "metadata": {
        "id": "4bQbmmAEFwff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c home-credit-default-risk\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 41
        },
        "id": "x8wfD0hLIg2B",
        "outputId": "46e10b27-96f3-400a-c796-20c8098dbf4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-997651fb-5eee-4f11-9f89-8b99ab3320cb\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-997651fb-5eee-4f11-9f89-8b99ab3320cb\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip home-credit-default-risk.zip"
      ],
      "metadata": {
        "id": "W5WMb7VXIk0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bureau = pd.read_csv('bureau.csv')\n",
        "bureau.head()"
      ],
      "metadata": {
        "id": "0rnBRzGXIr1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bureau 데이터프레임을 'SK_ID_CURR'로 그룹화하고, 'SK_ID_BUREAU'열을 count하여 'previous_loan_counts'라는 새로운 열을 생성\n",
        "previous_loan_counts = bureau.groupby(\n",
        "    'SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\n",
        "\n",
        "previous_loan_counts.head()"
      ],
      "metadata": {
        "id": "B7Lbj5-bI1it"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('application_train.csv')\n",
        "\n",
        "#이전 대출 횟수 정보를 'train' 데이터프레임과 합침침\n",
        "train = train.merge(previous_loan_counts, on = 'SK_ID_CURR', how='left')\n",
        "\n",
        "#'previous_loan_counts' 열에서 결측값이 있으면 0\n",
        "train['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\n",
        "train.head()"
      ],
      "metadata": {
        "id": "GQt65V-7JQvl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### r값을 이용한 새로운 변수의 유용성 평가\n",
        "- 새 변수가 유용한지 여부를 확인하기 위해 이 변수와 목표값 사이의 피어슨 상관 계수(r-값)를 계산할 수 있습니다. 이 값은 두 변수 사이의 선형 관계의 강도를 측정하며 -1(완전히 음의 선형)에서 +1(완전히 양의 선형)까지의 범위를 갖습니다. \n",
        "\n",
        "- r-값은 새 변수의 \"유용성\"에 대한 최상의 척도는 아니지만 변수가 기계 학습 모델에 도움이 되는지 여부에 대한 첫 번째 근사치를 제공할 수 있습니다. 목표값에 대한 변수의 r-값이 클수록 이 변수의 변화는 목표값에 더 많은 영향을 미칠 수 있습니다. 따라서 목표값과 관련하여 절대값 r-값이 가장 큰 변수를 찾습니다.\n",
        "\n",
        "- 또한 커널 밀도 추정(KDE) 그림을 사용하여 대상과의 관계를 시각적으로 검사할 수 있습니다."
      ],
      "metadata": {
        "id": "ENvU1vcfKBrQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Kernel Density Estimate Plots\n",
        "\n",
        "- 커널 밀도 추정치 그림은 단일 변수의 분포를 보여줍니다(평활 히스토그램이라고 생각). 범주형 변수의 값에 따라 다른 분포를 보려면 범주에 따라 분포에 색을 다르게 지정할 수 있습니다. 예를 들어 TARGET = 1인지 0인지에 따라 색상이 지정된 이전_count_count의 커널 밀도 추정치를 표시할 수 있습니다. 결과 KDE는 대출금을 상환하지 않은 사람(TARGET == 1)과 상환한 사람(TARGET == 0) 간의 변수 분포에서 유의한 차이를 보여줍니다. 이는 변수가 기계 학습 모델과 '관련성'이 있는지 여부를 나타내는 지표가 될 수 있습니다."
      ],
      "metadata": {
        "id": "we9poJzkKOr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def kde_target(var_name, df):\n",
        "  '''\n",
        "  변수의 TARGET과의 상관 관계를 계산하고, \n",
        "  TARGET 값이 0인 경우와 1인 경우 각각의 변수 분포를 비교하여 시각화\n",
        "  '''\n",
        "  #상관관계 계산 \n",
        "  corr = df['TARGET'].corr(df[var_name])\n",
        "  \n",
        "  #target이 1인 경우와 0인 경우의 각각의 중앙값\n",
        "  avg_repaid = df.loc[df['TARGET']==0, var_name].median()\n",
        "  avg_not_repaid = df.loc[df['TARGET']==1, var_name].median()\n",
        "\n",
        "  #kde plot 생성성\n",
        "  plt.figure(figsize=(12,6))\n",
        "  sns.kdeplot(df.loc[df['TARGET']==0, var_name], label = 'TARGET == 0')\n",
        "  sns.kdeplot(df.loc[df['TARGET']==1, var_name], label = 'TARGET == 1')\n",
        "\n",
        "  plt.xlabel(var_name)\n",
        "  plt.ylabel('Density')\n",
        "  plt.title('%s Distribution' %var_name)\n",
        "  plt.legend()\n",
        "\n",
        "  print('The correlation between %s and the TARGET is %0.4f' %(var_name, corr))\n",
        "  print('Median value for loan that was not repaid = %0.4f' % avg_not_repaid)\n",
        "  print('Median value for loan that was repaid     = %0.4f' %avg_repaid)"
      ],
      "metadata": {
        "id": "rHr1JktvJqQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "랜덤 포레스트 및 그라데이션 부스팅 머신에 따르면 가장 중요한 변수 중 하나인 EXT_SOURCE_3 변수를 사용하여 이 함수를 테스트할 수 있습니다."
      ],
      "metadata": {
        "id": "tbxAHZJhL5Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kde_target('EXT_SOURCE_3', train)"
      ],
      "metadata": {
        "id": "YC_mgSldLwqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 우리가 방금 만든 새로운 변수, 다른 기관의 이전 대출 수를 보겠습니다."
      ],
      "metadata": {
        "id": "RXCnRSXGMk4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kde_target('previous_loan_counts', train)"
      ],
      "metadata": {
        "id": "3JzZupcAL2GM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이로 인해 이 변수가 중요한지 여부를 판단하기가 어렵습니다. 상관 계수는 매우 약하며 분포에서 거의 눈에 띄는 차이가 없습니다.\n",
        "\n",
        "- 다음으로 bureau 데이터 프레임에서 몇 가지 변수를 더 만들어 보겠습니다. bureau 데이터 프레임에 있는 모든 숫자 열의 평균, 최소값 및 최대값을 사용합니다."
      ],
      "metadata": {
        "id": "Ny8j7dm2NDce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregating Numeric Columns\n",
        "\n",
        " - bureau 데이터 프레임의 숫자 정보를 설명하기 위해 모든 숫자 열에 대한 통계를 계산할 수 있습니다. \n",
        " \n",
        " - 이를 위해 클라이언트 ID별로 그룹화하고 그룹화된 데이터 프레임을 집계한 후 결과를 교육 데이터에 다시 병합합니다. \n",
        " \n",
        " - agg 함수는 작업이 유효한 것으로 간주되는 숫자 열의 값만 계산합니다. 우리는 'mean', 'max', 'min', 'sum'을 계속 사용할 것이지만, 여기에는 어떤 기능도 전달될 수 있습니다. 우리는 우리 자신의 기능을 작성하여 agg 호출에 사용할 수도 있습니다."
      ],
      "metadata": {
        "id": "aTITkT75NMa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'SK_ID_BUREAU' 열을 삭제하고 'SK_ID_CURR'을 기준으로 그룹화하고,\n",
        "# count, mean, max, sum  계산하여 bureau_agg 생성성\n",
        "\n",
        "bureau_agg = bureau.drop(columns = ['SK_ID_BUREAU']).groupby('SK_ID_CURR', as_index = False\n",
        "                                                             ).agg(['count', 'mean', 'max', 'sum']).reset_index()\n",
        "bureau_agg.head()"
      ],
      "metadata": {
        "id": "8pcqj-VJM4EC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 각 열에 대해 새 이름을 만들어야 합니다. 다음 코드는 이름에 통계를 추가하여 새 이름을 만듭니다. \n",
        "\n",
        "- 여기서 우리는 데이터 프레임에 다단계 인덱스가 있다는 사실을 다루어야 합니다. 저는 이런 것들이 혼란스럽고 다루기가 어렵다고 생각하기 때문에 가능한 한 빨리 단일 수준의 색인으로 줄이려고 노력합니다."
      ],
      "metadata": {
        "id": "ccY-n1YwNufh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#bureau_agg 데이터프레임에서 각 변수 별로 count, mean, max, sum을 계산한 결과를 가지고 \n",
        "#새로운 변수명을 생성하고 이를 columns 리스트에 추가\n",
        "\n",
        "columns = ['SK_ID_CURR']\n",
        "\n",
        "for var in bureau_agg.columns.levels[0]:\n",
        "  if var != 'SK_ID_CURR':\n",
        "    #각 변수마다 count, mean, max, sum을 계산한 결과에 대해서, \n",
        "    #새로운 변수명을 생성하고 columns 리스트에 추가\n",
        "    for stat in bureau_agg.columns.levels[1][:-1]:\n",
        "      columns.append('bureau_%s_%s' %(var, stat))"
      ],
      "metadata": {
        "id": "99mMMjc7Nrnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_agg.columns = columns\n",
        "bureau_agg.head()"
      ],
      "metadata": {
        "id": "k2teIPqxPRQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 이전과 같이 교육 데이터와 병합합니다"
      ],
      "metadata": {
        "id": "B0TC1dnaPZE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.merge(bureau_agg, on='SK_ID_CURR', how='left')\n",
        "train.head()"
      ],
      "metadata": {
        "id": "5vHwf3gEPVJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlations of Aggregated Values with Target\n",
        "\n",
        "- 우리는 모든 새로운 값과 목표값의 상관관계를 계산할 수 있습니다. 다시, 우리는 이것들을 모델링에 중요할 수 있는 변수의 근사치로 사용할 수 있습니다."
      ],
      "metadata": {
        "id": "bfQveRLwPg2x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_corrs = []\n",
        "\n",
        "for col in columns:\n",
        "  corr = train['TARGET'].corr(train[col])\n",
        "  new_corrs.append((col, corr))"
      ],
      "metadata": {
        "id": "c7Z3B9glPfza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 아래 코드에서는 정렬된 Python 함수를 사용하여 크기(절대값)에 따라 상관관계를 정렬합니다. 우리는 또한 알아두면 좋은 또 다른 중요한 파이썬 작업인 익명 람다 함수를 사용합니다."
      ],
      "metadata": {
        "id": "DczV1OLFP8au"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_corrs = sorted(new_corrs, key=lambda x:abs(x[1]), reverse = True)\n",
        "new_corrs[:15]"
      ],
      "metadata": {
        "id": "86XAnm7OP0J9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 새 변수 중 대상과 유의한 상관 관계가 있는 변수가 없습니다. 상관관계가 가장 높은 변수인 bureau_의 KDE 그림을 볼 수 있습니다DAYS_Credit_mean(대상이 절대 크기 상관 관계)입니다."
      ],
      "metadata": {
        "id": "ejMETHNsSetF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kde_target('bureau_DAYS_CREDIT_mean', train)"
      ],
      "metadata": {
        "id": "6MaQTQhOSb0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이 변수는 \"현재 대출 신청 전에 고객이 Credit Bureau credit을 신청한 일 수\"를 나타냅니다. \n",
        "\n",
        "- 내 해석은 이것이 홈 크레딧에서 대출을 신청하기 전에 이전 대출을 가입한 날짜의 수입니다. 따라서 더 큰 음수는 대출이 현재 대출 신청보다 더 이전에 신청되었음을 나타냅니다. \n",
        "\n",
        "- 이 변수의 평균과 target 간에는 매우 약한 양의 관계가 있습니다. 이는 이전에 대출을 신청한 고객이 Home Credit 대출을 상환할 가능성이 높다는 것을 나타냅니다. 그러나 상관관계가 이렇게 약하면 신호(signal)일 가능성과 노이즈(noise)일 가능성이 동등하게 높습니다."
      ],
      "metadata": {
        "id": "45pqudFTSowM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The Multiple Comparisons Problem\n",
        "\n",
        "- 많은 변수가 있을 때, 우리는 그들 중 일부가 순전히 우연에 의해 상관 관계를 맺을 것으로 예상합니다. \n",
        "\n",
        "- 이는 다중 비교로 알려진 문제입니다. 우리는 수백 개의 기능을 만들 수 있으며, 일부 기능은 단순히 데이터의 무작위 노이즈 때문에 대상과 연관되어 있는 것으로 밝혀질 것입니다. \n",
        "\n",
        "- 그런 다음, 우리 모델이 훈련할 때, 훈련 세트의 대상과 관계가 있다고 생각하기 때문에 이러한 변수에 지나치게 적합할 수 있지만, 이것이 반드시 테스트 세트로 일반화되는 것은 아닙니다. 기능을 만들 때 고려해야 할 많은 고려 사항이 있습니다!"
      ],
      "metadata": {
        "id": "IXTHJmuOSrC3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function for Numeric Aggregations\n",
        "\n",
        "앞의 모든 작업을 함수로 캡슐화해 보겠습니다. 이를 통해 모든 데이터 프레임에서 숫자 열의 집계 통계를 계산할 수 있습니다. 다른 데이터 프레임에도 동일한 작업을 적용하고자 할 때 이 기능을 다시 사용합니다.\n"
      ],
      "metadata": {
        "id": "2lXgRI8XSwNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def agg_numeric(df, group_var, df_name):\n",
        "  '''\n",
        "  주어진 데이터프레임에서 수치형 열에 대한 집계 통계량을 계산하고, \n",
        "  지정된 그룹 변수(group_var)로 그룹화하여 결과를 반환\n",
        "  '''\n",
        "  for col in df:\n",
        "    #group_var를 제외한 모든 'SK_ID'로 시작하는 열을 삭제\n",
        "    if col != group_var and 'SK_ID' in col:\n",
        "      df = df.drop(columns = col)\n",
        "  \n",
        "  group_ids = df[group_var]\n",
        "  #number데이터만 선택\n",
        "  numeric_df = df.select_dtypes('number')\n",
        "  numeric_df[group_var] = group_ids\n",
        "\n",
        "  #수치형 변수의 개수(count), 평균(mean), 최댓값(max), 최솟값(min), 합(sum)을 계산\n",
        "  agg = numeric_df.groupby(group_var).agg(['count', 'mean', 'max', 'min', 'sum']).reset_index()\n",
        "\n",
        "  columns = [group_var]\n",
        "\n",
        "  for var in agg.columns.levels[0]:\n",
        "    if var != group_var:\n",
        "      for stat in agg.columns.levels[1][:-1]:\n",
        "        columns.append('%s_%s_%s' %(df_name, var, stat))\n",
        "    \n",
        "  agg.columns = columns\n",
        "  return agg"
      ],
      "metadata": {
        "id": "zbvz4SCbSkr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_agg_new = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
        "bureau_agg_new.head()"
      ],
      "metadata": {
        "id": "7up_8XgvTQU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기능이 의도한 대로 작동하는지 확인하려면 수작업으로 구축한 집계 데이터 프레임과 비교해야 합니다."
      ],
      "metadata": {
        "id": "PJsqbjCYUBUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_agg.head()"
      ],
      "metadata": {
        "id": "Vl5GqGMnTw_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리가 그 값들을 조사해 보면, 우리는 그것들이 동등하다는 것을 알게 됩니다. 우리는 이 기능을 다른 데이터 프레임에 대한 숫자 통계를 계산하는 데 재사용할 수 있습니다. 기능을 사용하면 일관된 결과를 얻을 수 있고 앞으로 해야 할 일의 양이 줄어듭니다!"
      ],
      "metadata": {
        "id": "yjiNdl2sUFgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "####Correlation Function\n",
        "\n",
        "다음으로 넘어가기 전에 대상과의 상관관계를 계산하는 코드를 함수로 만들 수도 있습니다."
      ],
      "metadata": {
        "id": "pOfyJ5WaUG0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def target_corrs(df):\n",
        "  corrs = []\n",
        "  for col in df.columns:\n",
        "    print(col)\n",
        "    if col != 'TARGET':\n",
        "      corr = df['TARGET'].corr(df[col])\n",
        "      corrs.append((col,corr))\n",
        "  corrs = sorted(corrs, key=lambda x: abs(x[1]), reverse = True)\n",
        "\n",
        "  return corrs"
      ],
      "metadata": {
        "id": "iCkHLs9eUDXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Categorical Variables\n",
        "\n",
        "이제 숫자 열에서 범주형 열로 이동합니다. 이러한 변수는 이산 문자열 변수이므로 숫자 변수에만 사용되는 평균 및 최대값과 같은 통계량을 계산할 수 없습니다. 대신 각 범주 변수 내에서 각 범주의 값 카운트를 계산합니다. "
      ],
      "metadata": {
        "id": "c3mfuAFqUdly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = pd.get_dummies(bureau.select_dtypes('object'))\n",
        "categorical['SK_ID_CURR'] = bureau['SK_ID_CURR']\n",
        "categorical.head()"
      ],
      "metadata": {
        "id": "LgEk1EFUUcmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_grouped = categorical.groupby('SK_ID_CURR').agg(['sum', 'mean'])\n",
        "categorical_grouped.head()"
      ],
      "metadata": {
        "id": "AJbUyUePUxTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 합 열은 연결된 클라이언트에 대한 해당 범주의 개수를 나타내고 평균은 정규화된 개수를 나타냅니다. 원핫 인코딩은 이러한 수치를 계산하는 과정을 매우 쉽게 만듭니다!\n",
        "\n",
        "- 이전과 유사한 기능을 사용하여 열 이름을 바꿀 수 있습니다. 다시 말씀드리지만, 우리는 컬럼에 대한 다단계 인덱스를 처리해야 합니다. 범주 값(원핫 인코딩에서)이 추가된 범주 변수의 이름인 첫 번째 수준(수준 0)을 통해 반복합니다. 그런 다음 각 클라이언트에 대해 계산한 통계를 반복합니다. stat에 0 수준 이름이 추가된 열 이름을 변경합니다. 예를 들어 CREDIT_ACTIVE_ACTIVE가 레벨 0이고 합계가 레벨 1인 열은 CREDIT_ACTIVE_ACTIVE_count가 됩니다."
      ],
      "metadata": {
        "id": "2pD8DnefVAs8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_grouped.columns.levels[0][:10]"
      ],
      "metadata": {
        "id": "RsX9y_pvU8iD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_grouped.columns.levels[1]"
      ],
      "metadata": {
        "id": "IIGzMEYWVGIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group_var = 'SK_ID_CURR'\n",
        "columns =[]\n",
        "\n",
        "for var in categorical_grouped.columns.levels[0]:\n",
        "  if var != group_var:\n",
        "    for stat in ['count', 'count_norm']:\n",
        "      columns.append('%s_%s' %(var, stat))\n",
        "\n",
        "categorical_grouped.columns = columns\n",
        "\n",
        "categorical_grouped.head()"
      ],
      "metadata": {
        "id": "5elWuMeuVIzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 합 열에는 카운트가 기록되고 평균 열에는 정규화된 카운트가 기록됩니다.\n",
        "- 이 데이터 프레임을 교육 데이터에 병합할 수 있습니다."
      ],
      "metadata": {
        "id": "Kv9ali6dVgmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.merge(categorical_grouped, left_on = 'SK_ID_CURR', right_index = True, how='left')\n",
        "train.head()"
      ],
      "metadata": {
        "id": "caAd0j2OVc-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "id": "izSxW0nlVtQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.iloc[:10, 123:]"
      ],
      "metadata": {
        "id": "8vQdXUd1VutK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to Handle Categorical Variables\n",
        "\n",
        "코드를 더 효율적으로 만들기 위해 이제 범주형 변수를 처리하는 함수를 작성할 수 있습니다. 이것은 데이터 프레임과 그룹화 변수를 수용한다는 점에서 agg_numeric 함수와 동일한 형식을 취할 것입니다. 그런 다음 데이터 프레임의 모든 범주형 변수에 대한 각 범주의 카운트와 정규화된 카운트를 계산합니다."
      ],
      "metadata": {
        "id": "0kKI1BzaVyG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_categorical(df, group_var, df_name):\n",
        "  categorical = pd.get_dummies(df.select_dtypes('object'))\n",
        "  categorical[group_var] = df[group_var]\n",
        "\n",
        "  categorical = categorical.groupby(group_var).agg(['sum', 'mean'])\n",
        "  column_names = []\n",
        "\n",
        "  for var in categorical.columns.levels[0]:\n",
        "    for stat in ['count', 'count_norm']:\n",
        "      column_names.append('%s_%s_%s' %(df_name, var, stat))\n",
        "\n",
        "  categorical.columns = column_names\n",
        "  return categorical"
      ],
      "metadata": {
        "id": "UY6YCEAVVw0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_counts = count_categorical(bureau, group_var ='SK_ID_CURR', df_name = 'bureau')\n",
        "bureau_counts.head()"
      ],
      "metadata": {
        "id": "SGWM4OkUWcxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applying Operations to another dataframe\n",
        "\n",
        "이제 bureau balance 데이터 프레임으로 넘어갑니다. 이 데이터 프레임에는 각 고객의 다른 금융 기관에 대한 이전 대출에 대한 월별 정보가 있습니다. 이 데이터 프레임을 SK로 그룹화하는 대신_클라이언트 ID인 ID_CURR, 먼저 데이터 프레임을 SK_별로 그룹화합니다이전 대출의 ID인 ID_Bureau입니다. 이렇게 하면 각 대출에 대해 데이터 프레임 행이 하나씩 제공됩니다. 그런 다음 SK_로 그룹화할 수 있습니다ID_CURR 및 각 클라이언트의 대출에 걸친 집계를 계산합니다. 최종 결과는 각 클라이언트에 대해 하나의 행이 있는 데이터 프레임이 되고, 각 클라이언트의 대출에 대해 통계가 계산됩니다."
      ],
      "metadata": {
        "id": "ucmf3CKmWvtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
        "bureau_balance.head()"
      ],
      "metadata": {
        "id": "wvDjrdZJWlk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저, 각 대출에 대한 각 상태의 가치 카운트를 계산할 수 있습니다. 다행히도, 우리는 이미 이것을 해주는 기능을 가지고 있습니다!"
      ],
      "metadata": {
        "id": "RHrrozqDXAc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
        "bureau_balance_counts.head()"
      ],
      "metadata": {
        "id": "DZriQ_58W74v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 하나의 숫자 열을 처리할 수 있습니다. MOONS_BALANCE 열에는 \"적용 날짜를 기준으로 잔액이 있는 달\"이 있습니다 이는 숫자 변수만큼 중요하지 않을 수 있으며, 향후 작업에서는 이를 시간 변수로 고려할 수 있습니다. 지금은 이전과 동일한 집계 통계만 계산하면 됩니다."
      ],
      "metadata": {
        "id": "fv6fKJ3_XUoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
        "bureau_balance_agg.head()"
      ],
      "metadata": {
        "id": "jAY580cfXOTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "위의 데이터 프레임에는 각 대출에 대해 계산이 수행됩니다. 이제 각 클라이언트에 대해 이를 집계해야 합니다. 먼저 데이터 프레임을 병합한 다음 모든 변수가 숫자이므로 통계를 다시 집계하면 됩니다. 이번에는 SK_ID_CURR를 기준으로 그룹화하면 됩니다"
      ],
      "metadata": {
        "id": "BB-lDgpUXi4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_by_loan = bureau_balance_agg.merge(bureau_balance_counts, right_index = True, left_on = 'SK_ID_BUREAU', how = 'outer')\n",
        "\n",
        "bureau_by_loan = bureau_by_loan.merge(bureau[['SK_ID_BUREAU', 'SK_ID_CURR']], on = 'SK_ID_BUREAU', how = 'left')\n",
        "bureau_by_loan.head()"
      ],
      "metadata": {
        "id": "EAoJIdR9XgnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')\n",
        "bureau_balance_by_client.head()"
      ],
      "metadata": {
        "id": "yvOgQQ8NYHbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 요약하자면 bureau_balance 데이터 프레임에 대해 다음과 같이 설명합니다:\n",
        "  - 각 대출별로 계산된 숫자 통계 그룹화\n",
        "  - 대출별 범주형 변수 그룹화의 만든 값 수\n",
        "  - 대출에 대한 통계 및 값 개수 병합\n",
        "  - 클라이언트 ID를 기준으로 결과 데이터 프레임 그룹화에 대해 계산된 숫자 통계\n",
        "\n",
        "- 최종 결과 데이터 프레임에는 각 클라이언트에 대해 하나의 행이 있으며, 월별 잔액 정보로 모든 대출에 대해 통계가 계산됩니다.\n",
        "\n",
        "- 이러한 변수 중 일부는 약간 혼란스러우므로 몇 가지 설명해 보겠습니다:\n",
        "  - client_bureau_balance_MONGS_BALANCE_mean_mean: 각 대출에 대해 MONGS_BALANCE의 평균값을 계산합니다. 그런 다음 각 고객에 대해 모든 대출에 대한 이 값의 평균을 계산합니다.\n",
        "  - client_bureau_balance_STATUS_X_count_norm_sum: 각 대출에 대해 발생 횟수 STATUS == X를 대출에 대한 총 STATUS 값으로 나눈 값을 계산합니다. 그런 다음 각 클라이언트에 대해 각 대출의 값을 합산합니다.\n",
        "\n",
        "- 우리는 모든 변수가 하나의 데이터 프레임에 통합될 때까지 상관 관계를 계산하는 것을 보류할 것입니다."
      ],
      "metadata": {
        "id": "n46LZrSoYmLU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Putting the Functions Together\n",
        "\n",
        "우리는 이제 다른 기관의 이전 대출금과 이 대출금에 대한 월별 지급 정보를 가져와서 주요 교육 데이터 프레임에 넣을 수 있는 모든 자료를 준비했습니다. 모든 변수를 재설정하고 처음부터 다시 설정하기 위해 만든 기능을 사용해 보겠습니다. 이것은 반복 가능한 워크플로우를 위해 기능을 사용하는 것의 이점을 보여줍니다!\n"
      ],
      "metadata": {
        "id": "XbUmOMg2ZA9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.enable()\n",
        "del train, bureau, bureau_balance, bureau_agg, bureau_agg_new, bureau_balance_agg, bureau_balance_counts, bureau_by_loan, bureau_balance_by_client, bureau_counts\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "rksJjVXuYhkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('application_train.csv')\n",
        "bureau = pd.read_csv('bureau.csv')\n",
        "bureau_balance = pd.read_csv('bureau_balance.csv')"
      ],
      "metadata": {
        "id": "k2_nbKTmZMA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Count of Bureau DataFrame"
      ],
      "metadata": {
        "id": "9TvgGkVzZbm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_counts = count_categorical(bureau, group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
        "bureau_counts.head(0)"
      ],
      "metadata": {
        "id": "lm6oZO-gZaun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Aggregated Stats of Bureau DataFrame"
      ],
      "metadata": {
        "id": "yiBy60eRZoBJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_agg = agg_numeric(bureau.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'bureau')\n",
        "bureau_agg.head()"
      ],
      "metadata": {
        "id": "WWL2FuIdZnGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Value counts of Bureau Balance dataframe by loan\n"
      ],
      "metadata": {
        "id": "YP9n_4lNaf6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_balance_counts = count_categorical(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
        "bureau_balance_counts.head()"
      ],
      "metadata": {
        "id": "dRU4TAaMadpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggregated stats of Bureau Balance dataframe by loan"
      ],
      "metadata": {
        "id": "U91tmUo3a1c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_balance_agg = agg_numeric(bureau_balance, group_var = 'SK_ID_BUREAU', df_name = 'bureau_balance')\n",
        "bureau_balance_agg.head()"
      ],
      "metadata": {
        "id": "Pshb5RPbawhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggregated Stats of Bureau Balance by Client"
      ],
      "metadata": {
        "id": "56miSUwjbGDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bureau_by_loan = bureau_balance_agg.merge(\n",
        "    bureau_balance_counts, right_index=True, left_on = 'SK_ID_BUREAU', how = 'left')\n",
        "\n",
        "bureau_by_loan = bureau[['SK_ID_BUREAU', 'SK_ID_CURR']].merge(bureau_by_loan, on = 'SK_ID_BUREAU', how ='left')\n",
        "\n",
        "bureau_balance_by_client = agg_numeric(bureau_by_loan.drop(columns = ['SK_ID_BUREAU']), group_var = 'SK_ID_CURR', df_name = 'client')"
      ],
      "metadata": {
        "id": "osZaouBbbEU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert Computed Features into Training Data"
      ],
      "metadata": {
        "id": "ZE3u3FpscRl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_features = list(train.columns)\n",
        "print('Original Number of Features: ', len(original_features))"
      ],
      "metadata": {
        "id": "088IzXubb4Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.merge(bureau_counts, on = 'SK_ID_CURR', how = 'left')\n",
        "train = train.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
        "train = train.merge(bureau_balance_by_client, on = 'SK_ID_CURR', how = 'left')"
      ],
      "metadata": {
        "id": "jOI_OKrVcbNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_features = list(train.columns)\n",
        "print('Number of features using previous loans from other institutions data: ', len(new_features))"
      ],
      "metadata": {
        "id": "OyTEG_XPclDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Feature Engineering Outcomes\n",
        "- 그 모든 작업이 끝난 후, 이제 우리는 우리가 만든 변수들을 살펴보려고 합니다. 결측값의 백분율, 변수와 대상의 상관 관계 및 변수와 다른 변수의 상관 관계를 살펴볼 수 있습니다. 변수 간의 상관 관계는 공선형 변수, 즉 서로 상관 관계가 높은 변수가 있는지 여부를 보여줄 수 있습니다. 종종 두 변수를 모두 갖는 것은 중복되기 때문에 공선형 변수 쌍에서 하나를 제거하려고 합니다. 또한 결측값의 백분율을 사용하여 존재하지 않는 값의 대부분이 포함된 형상을 제거할 수 있습니다. 특징의 수를 줄이는 것은 모델이 훈련 중에 학습하는 데 도움이 되고 테스트 데이터에 더 잘 일반화될 수 있기 때문에 앞으로 특징 선택이 중요할 것입니다. 차원의 저주는 너무 많은 기능(차원이 너무 높음)으로 인해 발생하는 문제에 지정된 이름입니다. 변수의 수가 증가함에 따라 이러한 변수와 목표값 간의 관계를 학습하는 데 필요한 데이터 점의 수가 기하급수적으로 증가합니다.\n",
        "\n",
        "- 기능 선택은 모델이 테스트 세트에 대해 더 잘 학습하고 일반화하는 데 도움이 되는 변수를 제거하는 프로세스입니다. 목적은 유용한 변수를 보존하면서 불필요한/중복 변수를 제거하는 것입니다. 이 프로세스에 사용할 수 있는 도구는 여러 가지가 있지만, 이 노트북에서는 결측값의 비율이 높은 열과 서로 상관 관계가 높은 변수를 제거하는 작업을 수행합니다. 나중에 그라데이션 부스팅 머신 또는 랜덤 포레스트와 같은 모델에서 반환된 기능 중요도를 사용하여 기능 선택을 수행하는 방법을 살펴볼 수 있습니다.\n"
      ],
      "metadata": {
        "id": "wNVgbQ2sc4Wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Missing Values\n",
        "중요한 고려 사항은 데이터 프레임의 결측값입니다. 결측값이 너무 많은 열은 삭제해야 할 수 있습니다."
      ],
      "metadata": {
        "id": "P_uHLkQtdAHO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def missing_values_table(df):\n",
        "  mis_val = df.isnull().sum()\n",
        "  mis_val_percent = 100*df.isnull().sum()/len(df)\n",
        "  mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "  mis_val_table_ren_columns = mis_val_table.rename(\n",
        "      columns = {0 : 'Missing Values', 1 : '% of Total Values'}\n",
        "  )\n",
        "  mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "      mis_val_table_ren_columns.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
        "\n",
        "  print('Your selected dataframe has ' + str(df.shape[1]) + ' columns.\\n'\n",
        "  'There are ' + str(mis_val_table_ren_columns.shape[0]) + 'columns that hace missing values.')\n",
        "\n",
        "  return mis_val_table_ren_columns"
      ],
      "metadata": {
        "id": "t7fpMMlDc3Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_train = missing_values_table(train)\n",
        "missing_train.head(10)"
      ],
      "metadata": {
        "id": "biPfRLz5eFWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측값의 비율이 높은 열이 여러 개 있습니다. 결측값을 제거하기 위한 정확한 임계값은 없으며 문제에 따라 최적의 조치가 달라집니다. 여기에서는 피쳐 수를 줄이기 위해 교육 또는 테스트 데이터에서 결측값이 90%보다 큰 열을 제거합니다."
      ],
      "metadata": {
        "id": "tB5uEwUOeV-S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_train_vars = list(missing_train.index[missing_train['% of Total Values']> 90])\n",
        "len(missing_train_vars)"
      ],
      "metadata": {
        "id": "YjNBlldEeKAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "결측값을 제거하기 전에 검정 데이터에서 결측값 백분율을 찾습니다. 그런 다음 교육 또는 테스트 데이터에서 결측값이 90% 이상인 열을 제거합니다. 이제 테스트 데이터를 읽고 동일한 작업을 수행한 후 테스트 데이터의 결측값을 살펴보겠습니다. 이미 모든 카운트 및 집계 통계를 계산했으므로 테스트 데이터를 적절한 데이터와 병합하기만 하면 됩니다."
      ],
      "metadata": {
        "id": "GHL3HMTneY81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Calculate Information for Testing Data"
      ],
      "metadata": {
        "id": "ojGyyoBwentg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('application_test.csv')\n",
        "test = test.merge(bureau_counts, on = 'SK_ID_CURR', how='left')\n",
        "test = test.merge(bureau_agg, on = 'SK_ID_CURR', how = 'left')\n",
        "test = test.merge(bureau_balance_by_client, on= 'SK_ID_CURR', how = 'left')"
      ],
      "metadata": {
        "id": "Lwz3PD1qepcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Shape of Testing Data: ', test.shape)"
      ],
      "metadata": {
        "id": "Y-hBexxHV-hN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "우리는 테스트 및 교육 데이터 프레임을 정렬해야 합니다. 즉, 열이 정확히 동일하도록 열을 일치시키는 것입니다. 이것은 여기서 문제가 되지 않지만, 원핫 인코딩 변수를 사용할 때 데이터 프레임을 정렬하여 동일한 열이 있는지 확인해야 합니다."
      ],
      "metadata": {
        "id": "l4N25Ny0WFO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = train['TARGET']\n",
        "train, test = train.align(test, join = 'inner', axis = 1)\n",
        "train['TARGET']=train_labels"
      ],
      "metadata": {
        "id": "StMJ3E0gWBaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training Data Shape: ', train.shape)\n",
        "print('Testing Data Shape: ', test.shape)"
      ],
      "metadata": {
        "id": "Wt3clVn4WQPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 데이터 프레임에 동일한 열이 있습니다(교육 데이터의 대상 열 제외). 이는 훈련 및 테스트 데이터 프레임 모두에서 동일한 열을 확인해야 하는 기계 학습 모델에서 사용할 수 있음을 의미합니다.\n",
        "\n",
        "- 이제 검정 데이터에서 결측값의 백분율을 확인하여 삭제해야 할 열을 알아보겠습니다."
      ],
      "metadata": {
        "id": "s8qBFz0TWg2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "missing_test = missing_values_table(test)\n",
        "missing_test.head(10)"
      ],
      "metadata": {
        "id": "6p43CQFcWZwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_test_vars = list(missing_test.index[missing_test['% of Total Values'] > 90])\n",
        "len(missing_test_vars)"
      ],
      "metadata": {
        "id": "0sgfZbu0Wo2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_columns = list(set(missing_test_vars + missing_train_vars))\n",
        "print('There are %d columns with more than 90%% missing in either the training or testing data.' % len(missing_columns))"
      ],
      "metadata": {
        "id": "AtIL7VN3WxhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns = missing_columns)\n",
        "test = test.drop(columns = missing_columns)"
      ],
      "metadata": {
        "id": "URZK1xVMW_tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결측값이 90%를 초과하는 열이 없기 때문에 이 라운드에서 열을 제거했습니다. 차원을 줄이기 위해 다른 형상 선택 방법을 적용해야 할 수도 있습니다.\n",
        "\n",
        "- 이 시점에서 교육 및 테스트 데이터를 모두 저장합니다. 누락된 열을 떨어뜨리는 데 다른 비율을 사용하여 결과를 비교해 볼 것을 권장합니다."
      ],
      "metadata": {
        "id": "ch0o9qzLXNEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.to_csv('train_bureau_raw.csv', index = False)\n",
        "test.to_csv('test_bureau_raw.csv', index = False)"
      ],
      "metadata": {
        "id": "ai2wlwbNXLFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Correlations\n",
        "먼저 변수와 대상의 상관관계를 살펴보겠습니다. 우리는 우리가 만든 모든 변수에서 (응용 프로그램에서) 이미 교육 데이터에 있는 변수보다 더 큰 상관관계를 가지고 있다는 것을 알 수 있습니다.\n"
      ],
      "metadata": {
        "id": "X7x18k9GXbsc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corrs = train.corr()"
      ],
      "metadata": {
        "id": "CRAQJNWeXaKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrs = corrs.sort_values('TARGET', ascending = False)\n",
        "pd.DataFrame(corrs['TARGET'].head(10))"
      ],
      "metadata": {
        "id": "Uq45pIshXu18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(corrs['TARGET'].dropna().tail(10))"
      ],
      "metadata": {
        "id": "9hEhfRMeX471"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 대상과 가장 높은 상관 관계가 있는 변수(물론 1의 상관 관계가 있는 대상 제외)는 우리가 만든 변수입니다. 하지만 변수가 상관관계가 있다고 해서 유용한 것은 아니며, 수백 개의 새로운 변수를 생성하면 일부 변수는 단순히 무작위 노이즈 때문에 대상과 상관관계가 있다는 것을 기억해야 합니다.\n",
        "\n",
        "- 상관 관계를 회의적으로 보면 새로 생성된 변수 중 몇 가지가 유용할 수 있습니다. 변수의 \"유용성\"을 평가하기 위해 모형에서 반환되는 기능 중요도를 살펴보겠습니다. 호기심을 위해 (그리고 함수를 이미 작성했기 때문에) 새로 생성된 변수 중 두 개의 kde 플롯을 만들 수 있습니다."
      ],
      "metadata": {
        "id": "BYbMcebtX_zB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kde_target(var_name='client_bureau_balance_MONTHS_BALANCE_count_mean', df=train)"
      ],
      "metadata": {
        "id": "intvuig4X8lr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 변수는 각 클라이언트의 대출당 월 평균 레코드 수를 나타냅니다. 예를 들어, 한 고객이 월별 데이터에 3, 4, 5개의 레코드가 있는 3개의 이전 대출을 가지고 있는 경우, 이 변수의 값은 4가 됩니다. 분포를 보면 대출 1건당 월평균 기록이 많은 고객일수록 홈크레디트로 대출금을 상환할 가능성이 높았습니다. 이 값을 너무 많이 읽지는 않지만, 이전에 신용 기록이 더 많은 고객이 일반적으로 대출을 상환할 가능성이 더 높다는 것을 나타낼 수 있습니다."
      ],
      "metadata": {
        "id": "xZDkFtF5YOAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kde_target(var_name = 'bureau_CREDIT_ACTIVE_Active_count_norm', df=train)"
      ],
      "metadata": {
        "id": "r2Q6f8ZrYHBl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이런 분포는 도처에 널려 있습니다. 이 변수는 Credit_ACTIVE 값이 Active인 이전 대출의 수를 클라이언트에 대한 이전 대출의 총 수로 나눈 값입니다. 여기서의 상관관계는 너무 약해서 우리가 어떤 결론을 도출해야 한다고 생각하지 않습니다!"
      ],
      "metadata": {
        "id": "GXg0JD_fYYPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Collinear Variables\n",
        "\n",
        "- 변수와 대상의 상관 관계뿐만 아니라 각 변수와 다른 모든 변수의 상관 관계도 계산할 수 있습니다. 이를 통해 데이터에서 제거해야 할 매우 선형적인 변수가 있는지 확인할 수 있습니다.\n",
        "\n",
        "- 다른 변수와 상관 관계가 0.8보다 큰 변수를 찾습니다.\n"
      ],
      "metadata": {
        "id": "0fmTWviHZ4_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.8\n",
        "above_threshold_vars={}\n",
        "for col in corrs:\n",
        "  above_threshold_vars[col] = list(corrs.index[corrs[col] > threshold])"
      ],
      "metadata": {
        "id": "tLsqGHd6YWDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이러한 고도로 상관된 변수 쌍 각각에 대해 변수 중 하나만 제거하려고 합니다. 다음 코드는 각 쌍 중 하나만 추가하여 제거할 변수 집합을 만듭니다."
      ],
      "metadata": {
        "id": "FFcj3fh6aQN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cols_to_remove = []\n",
        "cols_seen = []\n",
        "cols_to_remove_pair = []\n",
        "\n",
        "for key, value in above_threshold_vars.items():\n",
        "    cols_seen.append(key)\n",
        "    for x in value:\n",
        "        if x == key:\n",
        "            next\n",
        "        else:\n",
        "            if x not in cols_seen:\n",
        "                cols_to_remove.append(x)\n",
        "                cols_to_remove_pair.append(key)\n",
        "\n",
        "cols_to_remove = list(set(cols_to_remove))\n",
        "print('Number of columns to remove: ', len(cols_to_remove))"
      ],
      "metadata": {
        "id": "e0vHh_09aNMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "교육 및 테스트 데이터 세트 모두에서 이러한 열을 제거할 수 있습니다. 이러한 변수를 제거한 후의 성능과 이러한 변수(이전에 저장한 원시 csv 파일)를 유지하는 성능을 비교해야 합니다."
      ],
      "metadata": {
        "id": "N66Q_nnRazTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_corrs_removed = train.drop(columns = cols_to_remove)\n",
        "test_corrs_removed = test.drop(columns = cols_to_remove)\n",
        "\n",
        "print('Training Corrs Removed Shape: ', train_corrs_removed.shape)\n",
        "print('Testing Corrs Removed Shape: ', test_corrs_removed.shape)"
      ],
      "metadata": {
        "id": "ZDKDm9J6a0IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_corrs_removed.to_csv('train_bureau_corrs_removed.csv', index = False)\n",
        "test_corrs_removed.to_csv('test_bureau_corrs_removed.csv', index=False)"
      ],
      "metadata": {
        "id": "HdFIVm1pasXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling\n",
        "\n",
        "- 이러한 새로운 데이터 세트의 성능을 실제로 테스트하기 위해 머신 러닝에 사용해 보겠습니다! 여기에서는 다른 노트북에서 개발한 기능을 사용하여 기능을 비교합니다(상관성이 높은 변수가 제거된 원시 버전). 우리는 이런 종류의 실험을 실행할 수 있으며, 경쟁사에 제출할 때 이 기능에 포함된 응용프로그램 데이터의 성능만 제어할 수 있습니다. 해당 성능을 이미 기록했으므로 제어 장치와 두 가지 테스트 조건을 나열할 수 있습니다:\n",
        "\n",
        "- 모든 데이터 세트에 대해 아래에 표시된 모델(정확한 하이퍼 파라미터 포함)을 사용합니다.\n",
        "\n",
        "  - control: 응용 프로그램 파일의 데이터만 표시됩니다.\n",
        "  - test 1: 응용 프로그램 파일의 데이터와 Bureau_balance 파일에서 기록된 모든 데이터\n",
        "  - test 2: 응용 프로그램 파일의 데이터와 bookief_balance 파일에서 모든 데이터가 기록되고 상관 관계가 높은 변수가 제거되었습니다.\n"
      ],
      "metadata": {
        "id": "AP9n8w4QbWTm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import gc\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "pnYqaljibVy-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model(features, test_features, encoding='ohe', n_folds=5):\n",
        "  #ids 추출\n",
        "  train_ids = features['SK_ID_CURR']\n",
        "  test_ids = test_features['SK_ID_CURR']\n",
        "  #트레이닝의 라벨 추출\n",
        "  labels = features['TARGET']\n",
        "  \n",
        "  #ids와 target 삭제\n",
        "  features = features.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
        "  test_features = test_features.drop(columns =['SK_ID_CURR'])\n",
        "\n",
        "  #On hot Encoding\n",
        "  if encoding == 'ohe':\n",
        "    features = pd.get_dummies(features)\n",
        "    test_features = pd.get_dummies(test_features)\n",
        "\n",
        "    features, test_features = features.align(test_features, join = 'inner', axis=1)\n",
        "    cat_indices = 'auto'\n",
        "\n",
        "  elif encoding == 'le':\n",
        "    label_encoder = LabelEncoder()\n",
        "    cat_indices = []\n",
        "\n",
        "    for i, col in enumerate(features):\n",
        "      if features[col].dtype == 'object':\n",
        "        features[col] = label_encoder.fit_transform(np.array(features[col].astype(str)).reshape((-1)))\n",
        "        test_features[col] = label_encoder.transform(np.array(test_features[col].astype(str)).reshape((-1)))\n",
        "        cat_indices.append(i)\n",
        "  \n",
        "  else:\n",
        "    raise ValueError(\"Encoding must be either 'ohe' or 'le'\")\n",
        "  \n",
        "  print('Training Data Shape: ', features.shape)\n",
        "  print('Testing Data Shape: ', test_features.shape)\n",
        "  \n",
        "  feature_names = list(features.columns)\n",
        "  features = np.array(features)\n",
        "  test_features = np.array(test_features)\n",
        "\n",
        "  k_fold = KFold(n_splits = n_folds, shuffle = False)\n",
        "\n",
        "  feature_importance_values = np.zeros(len(feature_names))\n",
        "  \n",
        "  test_predictions = np.zeros(test_features.shape[0])\n",
        "\n",
        "  out_of_fold = np.zeros(features.shape[0])\n",
        "\n",
        "  valid_scores = []\n",
        "  train_scores = []\n",
        "\n",
        "  for train_indices, valid_indices in k_fold.split(features):\n",
        "    train_features, train_labels = features[train_indices], labels[train_indices]\n",
        "    valid_features, valid_labels = features[valid_indices], labels[valid_indices]\n",
        "    model = lgb.LGBMClassifier(n_estimators=10000, objective = 'binary', \n",
        "                               class_weight = 'balanced', learning_rate = 0.05,\n",
        "                               reg_alpha = 0.1, reg_lambda=0.1,\n",
        "                               subsample = 0.8, n_jobs = -1, random_state = 50)\n",
        "    \n",
        "    model.fit(train_features, train_labels, eval_metric='auc',\n",
        "                eval_set = [(valid_features, valid_labels),(train_features, train_labels)],\n",
        "                eval_names = ['valid', 'train'], categorical_feature = cat_indices,\n",
        "              early_stopping_rounds = 100, verbose = 200)\n",
        "    best_iteration = model.best_iteration_\n",
        "    feature_importance_values += model.feature_importances_ /k_fold.n_splits\n",
        "\n",
        "    test_predictions += model.predict_proba(test_features, num_iteration = best_iteration)[:, 1] / k_fold.n_splits\n",
        "    out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = best_iteration)[:, 1]\n",
        "\n",
        "    valid_score = model.best_score_['valid']['auc']\n",
        "    train_score = model.best_score_['train']['auc']\n",
        "\n",
        "    valid_scores.append(valid_score)\n",
        "    train_scores.append(train_score)\n",
        "\n",
        "    gc.enable()\n",
        "    del model, train_features, valid\n",
        "    gc.collect()\n",
        "\n",
        "    submission = pd.DataFrame({'SK_ID_CURR': test_ids, 'TARGET': test_predictions})\n",
        "    feature_importances = pd.DataFrame({'feature': feature_names, 'importance': feature_importance_values})\n",
        "\n",
        "    valid_auc = roc_auc_score(labels, out_of_fold)\n",
        "\n",
        "    valid_scores.append(valid_auc)\n",
        "    train_scores.append(np.mean(train_scores))\n",
        "\n",
        "    fold_names = list(range(n_folds))\n",
        "    fold_names.append('overall')\n",
        "\n",
        "    metrics = pd.DataFrame({'fold': fold_names,\n",
        "                            'train': train_scores,\n",
        "                            'valid': valid_scores})\n",
        "    \n",
        "    return submission, feature_importances, metrics"
      ],
      "metadata": {
        "id": "awMmMI6Pb2hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importances(df):\n",
        "  df = df.sort_values('importance',ascending = False).reset_index()\n",
        "  df['importance_normalized'] = df['importance']/df['importance'].sum()\n",
        "\n",
        "  plt.figure(figsize = (10,6))\n",
        "  ax = plt.subplot()\n",
        "\n",
        "  ax.barh(list(reversed(list(df.index[:15]))),\n",
        "          df['importance_normalized'].head(15),\n",
        "          align = 'center', edgecolor = 'k')\n",
        "  \n",
        "  ax.set_yticks(list(reversed(list(df.index[:15]))))\n",
        "  ax.set_yticklabels(df['feature'].head(15))\n",
        "\n",
        "  plt.xlabel('Normalized Importance') \n",
        "  plt.title('Feature Importances')\n",
        "  plt.show()\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "zDaHAPihgljb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Control\n",
        "모든 실험의 첫 번째 단계는 관리 수준을 설정하는 것입니다. 이를 위해 위에 정의된 기능(그라데이션 부스팅 머신 모델을 구현하는 기능)과 단일 메인 데이터 소스(애플리케이션)를 사용합니다.\n"
      ],
      "metadata": {
        "id": "DUCzlvg1henU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_control = pd.read_csv('application_train.csv')\n",
        "test_control = pd.read_csv('application_test.csv')"
      ],
      "metadata": {
        "id": "rI378CJshX67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다행히도 함수를 작성하는 데 시간을 들인 후에는 함수를 사용하는 것이 간단합니다(이 노트에 중심 테마가 있는 경우에는 함수를 사용하여 작업을 단순하고 재현 가능하게 합니다!). 위의 함수는 경쟁사에 업로드할 수 있는 제출 데이터 프레임, 기능 중요도의 fi 데이터 프레임 및 검증 및 테스트 성능이 포함된 메트릭 데이터 프레임을 반환합니다."
      ],
      "metadata": {
        "id": "s7KRKxLrhw7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission, fi, metrics = model(train_control, test_control)"
      ],
      "metadata": {
        "id": "IjhN-gNjhuHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics"
      ],
      "metadata": {
        "id": "j0Qym--th2BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 교육 점수가 유효성 검사 점수보다 높기 때문에 컨트롤이 약간 오버핏됩니다. 정규화를 검토할 때 이후 노트북에서 이 문제를 해결할 수 있습니다(이 모델에서는 이미 reg_lambda 및 reg_alpha와 조기 중지를 사용하여 일부 정규화를 수행합니다).\n",
        "\n",
        "- flot_feature_importance라는 다른 함수를 사용하여 형상 중요도를 시각화할 수 있습니다. 형상 중요도는 형상을 선택할 때 유용할 수 있습니다.\n"
      ],
      "metadata": {
        "id": "TLd4AxVoj7Bz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fi_sorted = plot_feature_importances(fi)"
      ],
      "metadata": {
        "id": "PEnY7V1Hh392"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv('contorl.csv', index=False)"
      ],
      "metadata": {
        "id": "4SLNJLAjkCMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "컨트롤은 경기에 제출할 때 0.745점을 받습니다"
      ],
      "metadata": {
        "id": "zWUoeLOOkRwm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test One\n",
        "첫 번째 테스트를 진행하겠습니다. 우리는 대부분의 작업을 수행하는 기능에 데이터를 전달하기만 하면 됩니다."
      ],
      "metadata": {
        "id": "oXzGB1PAkTG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_raw, fi_raw, metrics_raw = model(train,test)"
      ],
      "metadata": {
        "id": "N12_fz9LkIep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_raw"
      ],
      "metadata": {
        "id": "HcKP-GrDkM4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이러한 수치를 바탕으로 설계된 기능이 제어 케이스보다 더 나은 성능을 발휘합니다. 그러나 이보다 더 나은 검증 성능이 테스트 데이터로 이전되는지 여부를 판단하기 전에 예측을 리더보드에 제출해야 합니다."
      ],
      "metadata": {
        "id": "_NHX9-Jekeaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fi_raw_sorted = plot_feature_importances(fi_raw)"
      ],
      "metadata": {
        "id": "6GILRxGykciz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "기능 개선 사항을 검토해 보면, 우리가 구성한 기능 중 몇 가지가 가장 중요한 기능인 것 같습니다. 이 노트북에서 만든 가장 중요한 100가지 기능 중에서 가장 중요한 기능의 비율을 알아보겠습니다. 그러나 단순히 원래 기능과 비교하는 것이 아니라 일회성으로 인코딩된 원래 기능과 비교해야 합니다. 이것들은 이미 (원래 데이터에서) fi에 기록되어 있습니다."
      ],
      "metadata": {
        "id": "ml7z5aL9kjwc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_100 = list(fi_raw_sorted['feature'])[:100]\n",
        "new_features = [x for x in top_100 if x not in list(fi['feature'])]\n",
        "print('%% of Teop 100 Feautres created from the bureau data = %d.00' %len(new_features))\n"
      ],
      "metadata": {
        "id": "ADoHjbqJki-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "상위 100개 기능 중 절반 이상이 저희가 만들었습니다! 그것은 우리가 한 모든 노력이 가치가 있다는 확신을 줄 것입니다."
      ],
      "metadata": {
        "id": "U1Fj6vtck3ym"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_raw.to_csv('test_one.csv', index = False)"
      ],
      "metadata": {
        "id": "uUQJhSGDk3H-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 1은 경기에 제출할 때 0.759점을 받습니다."
      ],
      "metadata": {
        "id": "oNDhWlrYlBeK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Test Two\n",
        "쉬웠으니까 한 번 더 뛰자구요! 이전과 동일하지만 매우 공선형 변수가 제거되었습니다."
      ],
      "metadata": {
        "id": "UQ4NvW4BlE4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_corrs, fi_corrs, metrics_corr = model(train_corrs_removed, test_corrs_removed)"
      ],
      "metadata": {
        "id": "EPAQo3yMlA7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_corr"
      ],
      "metadata": {
        "id": "ucK0L869lPAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이러한 결과는 관리보다는 낫지만 원시 피쳐보다는 약간 낮습니다."
      ],
      "metadata": {
        "id": "JApFi-3ulUMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fi_corrs_sorted = plot_feature_importances(fi_corrs)"
      ],
      "metadata": {
        "id": "N2qgn8NslTX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_corrs.to_csv('test_two.csv', index=False)"
      ],
      "metadata": {
        "id": "u7eReEmjlaSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "테스트 2는 경기에 제출할 때 0.753점을 받습니다."
      ],
      "metadata": {
        "id": "euxOgZK_lhBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results\n",
        "\n",
        "- 그 모든 작업 후에, 우리는 추가 정보를 포함하는 것이 성능을 향상시켰다고 말할 수 있습니다! 이 모델은 확실히 데이터에 최적화되지 않았지만 계산된 기능을 사용할 때 원래 데이터 세트보다 눈에 띄게 개선되었습니다. 성과를 공식적으로 요약해 보겠습니다:\n",
        "\n",
        "- 실험 열차 AUC 검증 AUC 테스트 AUC\n",
        "제어 0.8150.7600.745\n",
        "검정 1 0.8370.7670.759\n",
        "검정 2개 0.826 0.765 0.753\n",
        "이러한 점수는 노트북의 실행에 따라 변경될 수 있습니다. 하지만 저는 일반적인 주문이 바뀌는 것을 보지 못했습니다.)\n",
        "\n",
        "- 우리의 모든 노력은 원래 테스트 데이터보다 0.014 ROCAUC의 작은 개선으로 이어집니다. 고도로 공선형 변수를 제거하면 성능이 약간 저하되므로 피쳐 선택을 위한 다른 방법을 고려하려고 합니다. 또한, 우리가 만든 기능 중 일부는 모델에 의해 판단되는 가장 중요한 기능 중 하나라고 말할 수 있습니다.\n",
        "\n",
        "- 이와 같은 경쟁에서 이 크기의 개선만으로도 리더보드에서 100개의 자리를 차지할 수 있습니다. 이 노트북과 같이 여러 가지 작은 개선을 통해 점차 더 나은 성능을 달성할 수 있습니다. 저는 다른 사람들이 이 결과를 사용하여 스스로 개선할 것을 권장하며, 다른 사람들을 돕기 위해 제가 취한 조치를 계속 문서화할 것입니다."
      ],
      "metadata": {
        "id": "fF8sNr5Jl4dI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Next Step\n",
        "앞으로 이 노트북에서 개발한 기능을 다른 데이터 세트에서 사용할 수 있습니다. 모델에 사용할 다른 4개의 데이터 파일이 남아 있습니다! 다음 노트북에서는 이러한 다른 데이터 파일의 정보(홈 크레딧의 이전 대출에 대한 정보 포함)를 교육 데이터에 통합합니다. 그런 다음 동일한 모델을 구축하고 더 많은 실험을 실행하여 기능 엔지니어링의 효과를 확인할 수 있습니다. 이 경쟁에서 더 많은 일을 해야 하고, 더 많은 성과를 내야 합니다! 다음 공책에서 뵙겠습니다."
      ],
      "metadata": {
        "id": "Ze5WIro5mEkM"
      }
    }
  ]
}